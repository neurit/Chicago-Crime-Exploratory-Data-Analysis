{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CPS \"Pop Stats\" Socioeconomic Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we simply take the PDFs provided by Open City and parse them into CSV files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tabula import read_pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first split the first two years PDFs into two seperate documents, as the content switches from raw values to percentages between even and odd pages. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitPDF(file_path):\n",
    "    ''' given file_path, opens pdf, splits into even and odd pages, writes both to respective folders '''\n",
    "    # open pdf reader object (file path exists by construction)\n",
    "    pdf = PyPDF2.PdfFileReader(open(file_path, \"rb\"))\n",
    "    \n",
    "    \n",
    "    # writer objects for storing odd and even pages\n",
    "    odd_pages = PyPDF2.PdfFileWriter()\n",
    "    even_pages = PyPDF2.PdfFileWriter()\n",
    "    \n",
    "    for page_num in range(0, pdf.numPages):\n",
    "        # if page number is odd\n",
    "        if (page_num + 1) % 2 != 0:\n",
    "            odd_pages.addPage(pdf.getPage(page_num))\n",
    "        else:\n",
    "            even_pages.addPage(pdf.getPage(page_num))\n",
    "            \n",
    "            \n",
    "    # get just file name, splitting / to remove directory\n",
    "    \n",
    "    (directory, file_name) = file_path.split(\"/\")\n",
    "    # odd pages are actual number estimates\n",
    "    with open(\"{}/Numbers - {}\".format(directory, file_name), \"wb\") as outputStream: #create new PDF\n",
    "        odd_pages.write(outputStream)\n",
    "        \n",
    "    # even pages are percentage estimates\n",
    "    with open(\"{}/Percentages - {}\".format(directory, file_name), \"wb\") as outputStream:\n",
    "        even_pages.write(outputStream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all census files from 2010 to 2011 stored in Census Tract Summaries folder (ignoring first .dstore)\n",
    "file_names = [\"Census Tract Summaries/\" + file for file in os.listdir(\"Census Tract Summaries\")[1:]]\n",
    "\n",
    "# split first two pdfs\n",
    "for file in file_names[:2]:\n",
    "    splitPDF(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get new file_names\n",
    "file_names = [\"Census Tract Summaries/\" + file for file in os.listdir(\"Census Tract Summaries\")[1:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now use the tabula package to quickly read the pdf tables into a dataframe (note: the package is a simple wrapper function for a java library, so java is a requirement to use it). \n",
    "\n",
    "Unfortunately, given the formatting, this process works best if you give the feed the package an \"area\" tuple, detailing what section of the document actually contains the data. Specifically, we open each PDF in MacOS Preview, and use the crop tool to select the table's area. We note the areas below in the following list.\n",
    "\n",
    "Similarly, we ignore the provided header, which gets incorrectly read as multiple rows, and manually provide them for each census. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function for converting Preview's coords to area tuple\n",
    "get_area = lambda left, top, width, height: (top, left, top + height, left+width)\n",
    "\n",
    "area2010_numbers = get_area(141, 45.19, 346.47, 691.47)\n",
    "area2011_numbers = get_area(136.88, 56.6, 296.15, 681.24)\n",
    "area_percent_2011 = get_area(134.19, 103.01, 295.91, 586.04)\n",
    "area2012 = get_area(15.37, 69.96, 730.77, 525.55)\n",
    "area2013 = get_area(35.89, 159.18, 1602.76, 1189.47)\n",
    "area2014 = get_area(37.66, 159.73, 1565.8, 1182.17)\n",
    "area2015 = get_area(34.84, 159.39, 1569.27, 1186.13)\n",
    "area2016 = get_area(16.27, 70.9, 736.39, 528.64)\n",
    "area2017 = get_area(15.13, 71.5, 738.09, 527.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names_2010 = [\"Tract\", \"Estimated Median Family Income\", \"Less Than High School\", \"High School\", \"Some College\",\n",
    "                \"College Graduate\", \"Graduate School\", \"Educational Attainment Score\", \"% of Single Parent-Households\"\n",
    "                , \"% of Owner Occupied Homes\", \"% of Population Speaking a Language Other than English\", \"Number of School-Age Children\"]\n",
    "\n",
    "census2010_numbers = read_pdf(file_names[0], pages= \"all\", area = area2010_numbers, \n",
    "                      pandas_options = {'header': None, 'names': column_names_2010, 'index_col': \"Tract\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names_2011 = [\"Tract\", \"Estimated Median Family Income\", \"Less Than High School\", \"High School\", \"Some College\",\n",
    "                \"College Graduate\", \"Graduate School\", \"Educational Attainment Score\", \"% of Single Parent-Households\"\n",
    "                , \"% of Owner Occupied Homes\", \"% of Population Speaking a Language Other than English\", \n",
    "                     \"Weighted Average ISAT Performance at Attendance Area Schools\", \"Number of School-Age Children\"]\n",
    "\n",
    "census2011_numbers = read_pdf(file_names[1], pages = \"all\", area = area2011_numbers, \n",
    "                      pandas_options = {'header': None, 'names': column_names_2011, 'index_col': 'Tract'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Tract'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-36cdb6cfb1c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m census2010_percent = read_pdf(file_names[2], pages = \"all\", pandas_options = \n\u001b[0;32m----> 7\u001b[0;31m                               {'header': None, 'names': percent_columns, 'index_col': 'Tract'})\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tabula/wrapper.py\u001b[0m in \u001b[0;36mread_pdf\u001b[0;34m(input_path, output_format, encoding, java_options, pandas_options, multiple_tables, **kwargs)\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0mpandas_options\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpandas_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpandas_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    707\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 709\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    710\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 455\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    456\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m         \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1067\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'skipfooter not supported for iteration'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1068\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1069\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1070\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1071\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'as_recarray'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1880\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1881\u001b[0;31m                     \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_col\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1882\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1883\u001b[0m                 values = self._maybe_parse_dates(values, i,\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Tract'"
     ]
    }
   ],
   "source": [
    "percent_columns = [\"Tract\", \"Estimated Median Family Income Percentile\", \"Educational Attainment Score Percentile\",\n",
    "                   \"% of Single Parent Households Percentile\", \"% of Owner Occupied Homes Percentile\", \n",
    "                   \"% of Population Speaking a Language Other than English Percentile\", \n",
    "                   \"5-Factor Socioeconomic Score\", \"5-Factor Socioeconomic Tier\"]\n",
    "\n",
    "census2010_percent = read_pdf(file_names[2], pages = \"all\", pandas_options = \n",
    "                              {'header': None, 'names': percent_columns, 'index_col': 'Tract'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Tract'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-d4da34a9fd7b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m census2011_percent = read_pdf(file_names[3], pages = \"all\", area = area_percent_2011, pandas_options = \n\u001b[0;32m---> 10\u001b[0;31m                               {'header': None, \"names\": percent_2011, 'index_col': \"Tract\"})\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tabula/wrapper.py\u001b[0m in \u001b[0;36mread_pdf\u001b[0;34m(input_path, output_format, encoding, java_options, pandas_options, multiple_tables, **kwargs)\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0mpandas_options\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpandas_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpandas_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    707\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 709\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    710\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 455\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    456\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m         \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1067\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'skipfooter not supported for iteration'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1068\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1069\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1070\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1071\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'as_recarray'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1880\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1881\u001b[0;31m                     \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_col\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1882\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1883\u001b[0m                 values = self._maybe_parse_dates(values, i,\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Tract'"
     ]
    }
   ],
   "source": [
    "percent_2011 = [\"Tract\", \"Estimated Median Family Income Percentile\", \"Educational Attainment Score Percentile\",\n",
    "                   \"% of Single Parent Households Percentile\", \"% of Owner Occupied Homes Percentile\", \n",
    "                   \"% of Population Speaking a Language Other than English Percentile\", \n",
    "                   \"Weighted Average ISAT Performance at Attendance Area Schools Percentile\", \n",
    "                   \"6-Factor Socioeconomic Score\", \"6-Factor Socioeconomic Tier\"]\n",
    "\n",
    "\n",
    "\n",
    "census2011_percent = read_pdf(file_names[3], pages = \"all\", area = area_percent_2011, pandas_options = \n",
    "                              {'header': None, \"names\": percent_2011, 'index_col': \"Tract\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The files from now on are combined and contain every column from both the numbers and percent files from the previous year. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy columns, extend with percentages\n",
    "column_names_2012 = column_names_2011[:]\n",
    "column_names_2012.extend(percent_2011[1:])\n",
    "\n",
    "column_names_2012 = column_names_2012[:21]\n",
    "\n",
    "census2012 = read_pdf(file_names[4], pages = \"all\", area = area2012, pandas_options = \n",
    "                      {'header': None, 'names': column_names_2012, 'index_col': 'Tract'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "census2013 = read_pdf(file_names[5], pages = 'all', area = area2013, pandas_options = \n",
    "                      {'header': None, 'names': column_names_2012, 'index_col': 'Tract'})\n",
    "\n",
    "census2014 = read_pdf(file_names[6], pages = 'all', area = area2014, pandas_options = \n",
    "                      {'header': None, 'names': column_names_2012, 'index_col': 'Tract'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From 2015 on, the performance metric switches from ISAT to NWEA, so the columns must also change. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names_2015 = column_names_2012[:]\n",
    "\n",
    "column_names_2015[11] = column_names_2015[11].replace(\"ISAT\", \"NWEA\")\n",
    "column_names_2015[-3] = column_names_2015[-3].replace(\"ISAT\", \"NWEA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "census2015 = read_pdf(file_names[7], pages = 'all', area = area2015, pandas_options = \n",
    "                      {'header': None, 'names': column_names_2015, 'index_col': 'Tract'})\n",
    "\n",
    "census2016 = read_pdf(file_names[8], pages = 'all', area = area2016, pandas_options = \n",
    "                      {'header': None, 'names': column_names_2015, 'index_col': 'Tract'})\n",
    "\n",
    "census2017 = read_pdf(file_names[9], pages = 'all', area = area2017, pandas_options = \n",
    "                      {'header': None, 'names': column_names_2015, 'index_col': 'Tract'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "census2010 = pd.merge(census2010_numbers, census2010_percent, left_index = True, right_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save files for external use. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "census2010.to_csv(\"Census Tract CSVs/Summary of Census Socioeconomic Data 2010-2011.csv\")\n",
    "census2011.to_csv(\"Census Tract CSVs/Summary of Census Socioeconomic Data 2011-2012.csv\")\n",
    "census2012.to_csv(\"Census Tract CSVs/Summary of Census Socioeconomic Data 2012-2013.csv\")\n",
    "census2013.to_csv(\"Census Tract CSVs/Summary of Census Socioeconomic Data 2013-2014.csv\")\n",
    "census2014.to_csv(\"Census Tract CSVs/Summary of Census Socioeconomic Data 2014-2015.csv\")\n",
    "census2015.to_csv(\"Census Tract CSVs/Summary of Census Socioeconomic Data 2015-2016.csv\")\n",
    "census2016.to_csv(\"Census Tract CSVs/Summary of Census Socioeconomic Data 2016-2017.csv\")\n",
    "census2017.to_csv(\"Census Tract CSVs/Summary of Census Socioeconomic Data 2017-2018.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
